{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports necessary Packages\n",
    "import numpy as np\n",
    "import scipy.stats as sps\n",
    "import pandas as pd\n",
    "\n",
    "# Specific Plotting Packages\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib import patches\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# sklearn\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "# Import Custom Packages\n",
    "import supplemental_funcs as sf\n",
    "import example_master as EM # sets values for example\n",
    "\n",
    "# to show in notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "* Bayesian Solution to Fixed Plate Problem\n",
    "* Bayesian Solution to Wobbly Plate Problem"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# this is a trick to autoreload modules that I want to save for later\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import my_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a random seed\n",
    "# np.random.seed(24513)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 14})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defines a general color pallette\n",
    "col_highlight = 'xkcd:yellow'\n",
    "col_blue = 'xkcd:sky'\n",
    "col_red = 'xkcd:red orange'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save all figures dictionary\n",
    "# fig_save_dictionary { 'filename' : figname }\n",
    "fig_all_master = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stationary or Wobbly Plate?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defines model map $Q:\\Lambda\\rightarrow\\mathcal{D}$ as:\n",
    "\n",
    "\\begin{align}\n",
    "Q(\\lambda)=\\begin{pmatrix}0.6 & 0.7 \\\\\n",
    "0.8 & 0.6\n",
    "\\end{pmatrix}\\cdot \\begin{pmatrix} \\lambda_1 \\\\ \\lambda_2 \\end{pmatrix} +3\n",
    "\\end{align}\n",
    "\n",
    "where $\\vec{x}_A=(0.6,0.7)$ and $\\vec{x}_B=(0.8,0.6)$ are the two locations and $y_0=3$ is the height of the plate above the origin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Linear Map X = ')\n",
    "print(EM.locX_mat)\n",
    "print()\n",
    "print('y0 = ',EM.y0)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use parameter file EM to define appropriate parameters\n",
    "n_obs = EM.n_obs # number of observations\n",
    "locations = EM.locX_mat # location of observations\n",
    "y0 = EM.y0\n",
    "\n",
    "# mean of parameter slope or true fixed value for the slope\n",
    "lam_mean = EM.lam_dagger\n",
    "\n",
    "# define the observed parameters\n",
    "obs_mean = EM.obs_mean\n",
    "obs_cov = EM.obs_cov\n",
    "obs_dist = sps.multivariate_normal(obs_mean,obs_cov)\n",
    "\n",
    "# obtain inverse lambda target distribution\n",
    "loc_inverse = EM.locX_mat_inv\n",
    "lam_cov = EM.lam_gen_cov\n",
    "lam_target_dist = sps.multivariate_normal(lam_mean,lam_cov)\n",
    "\n",
    "# observed sample\n",
    "q_obs = obs_dist.rvs(n_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(obs_mean)\n",
    "print(obs_cov)\n",
    "print(lam_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Different Scenario Solutions\n",
    "\n",
    "Here I plot the data space and the corresponding inverse solutions in the parameter space for the two different kinds of problems:\n",
    "\n",
    "1. Parameter **Estimation** Problem\n",
    "2. Parameter **Distribution** Problem\n",
    "\n",
    "These correspond to a situation where the plate has a fixed slope (stationary plate) or has a random slope (wobbly plate), respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get eigenvalues and eigenvectors of matrix\n",
    "eig_val, eig_vec = np.linalg.eig(obs_cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make lam-sapce grid\n",
    "lamx = np.linspace(-8, 8, 100)\n",
    "lamy = np.linspace(-8, 8, 100)\n",
    "lamX, lamY = np.meshgrid(lamx, lamy)\n",
    "eval_lamXY = np.vstack([lamX.ravel(),lamY.ravel()])\n",
    "\n",
    "\n",
    "# make data-space grid\n",
    "qx = np.linspace(0, 6, 100)\n",
    "qy = np.linspace(0, 6, 100)\n",
    "qX, qY = np.meshgrid(qx, qy)\n",
    "eval_qXY = np.vstack([qX.ravel(),qY.ravel()])\n",
    "\n",
    "# eval points and reshape\n",
    "Z1 = lam_target_dist.pdf(eval_lamXY.T).reshape(lamX.shape)\n",
    "Z2 = obs_dist.pdf(eval_qXY.T).reshape(qX.shape)\n",
    "\n",
    "# parameter estimation: sampling distribution\n",
    "this_n = 10\n",
    "lam_hat_dist = sps.multivariate_normal(lam_mean,1/this_n*lam_cov)\n",
    "Z_hat = lam_hat_dist.pdf(eval_lamXY.T).reshape(lamX.shape)\n",
    "\n",
    "# decompose the eigenvalue matrix of lam\n",
    "exlam_eig, exlam_eigV =  np.linalg.eig(lam_cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for making the ellipses easier\n",
    "def make_cov_ellipse(center,cov,area=0.9,ellipse_args={}):\n",
    "    # sets an area for the circles that includes area% of data\n",
    "    this_area = sps.chi2.ppf(area,df=2) \n",
    "    this_center = center\n",
    "    \n",
    "    # eigen decomp covariance for ellipse parameters\n",
    "    this_eig_decomp = np.linalg.eig(cov)\n",
    "    \n",
    "    # eigen value widths and heights\n",
    "    this_eig0, this_eig1 = this_eig_decomp[0]\n",
    "    this_width = 2*np.sqrt(this_area/2*this_eig0)\n",
    "    this_height = 2*np.sqrt(this_area/2*this_eig1)\n",
    "    \n",
    "    # rotation\n",
    "    this_eig_vec = this_eig_decomp[1][:,0]\n",
    "    rot_angle = np.arctan(this_eig_vec[1]/this_eig_vec[0])*180/np.pi\n",
    "\n",
    "    this_ellipse = patches.Ellipse(xy=this_center,angle=rot_angle,\n",
    "                               width=this_width,height=this_height,\n",
    "                               **ellipse_args)\n",
    "    return this_ellipse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_intro_solutions, axes = plt.subplots(2,2)\n",
    "fig_intro_solutions.tight_layout()\n",
    "fig_intro_solutions.set_figwidth(8)\n",
    "fig_intro_solutions.set_figheight(8)\n",
    "\n",
    "these_ellipse_args = {'fc':'None','edgecolor':'C1','alpha':0.7}\n",
    "this_cycler = plt.rcParams['axes.prop_cycle']\n",
    "colors = this_cycler.by_key()['color']\n",
    "# create 4 figure\n",
    "for i,ax_row in enumerate(axes):\n",
    "    for j,ax in enumerate(ax_row):\n",
    "        # lambda space\n",
    "        if j==0:\n",
    "            if i==1:\n",
    "                contour = ax.contour(lamX,lamY,Z1)\n",
    "                ax.set_title('Parameter Distribution Solution')\n",
    "                ax.plot(lam_mean[0],lam_mean[1],'or',label='$\\mu_{\\lambda}$')\n",
    "            else:\n",
    "                for k,n in enumerate([1,5,20]):\n",
    "                    these_ellipse_args['edgecolor'] = colors[k+1]\n",
    "                    this_ellipse = make_cov_ellipse(lam_mean,1/n*lam_cov,area=0.99,\n",
    "                                                    ellipse_args=these_ellipse_args)\n",
    "                    ax.add_artist(this_ellipse)\n",
    "                    \n",
    "                    # label curves\n",
    "                    exlam_eig\n",
    "                    this_loc = lam_mean+0.6*1/n*exlam_eig[1]*exlam_eigV[:,1]\n",
    "                    adjusts = [np.array([0,0]),np.array([0,-1.5]),np.array([0.5,0.6])]\n",
    "                    halign = 'right' if k==0 else 'left'\n",
    "                    ax.annotate('$n={}$'.format(n),xy=this_loc+adjusts[k],\n",
    "                               color=colors[k+1],va='top',ha=halign)\n",
    "                    \n",
    "                ax.set_xlim(lamx[0],lamx[-1])\n",
    "                ax.set_ylim(lamy[0],lamy[-1])\n",
    "                ax.set_title('Parameter Estimation Solution')\n",
    "                ax.plot(lam_mean[0],lam_mean[1],'or',label='$\\\\hat{\\lambda}$')\n",
    "            ax.set_xlabel('$\\lambda_1$')\n",
    "            ax.set_ylabel('$\\lambda_2$')\n",
    "            \n",
    "#             contour.collections[-4].set_label('Random Slope')\n",
    "            ax.legend()\n",
    "            \n",
    "        else:\n",
    "            ax.contour(qX,qY,Z2)\n",
    "#             ax_dat.annotate('',xy=obs_mean-2.5*eig_val[1]*eig_vec[:,1],xytext=obs_mean,\n",
    "#                             arrowprops=dict(arrowstyle='->'))\n",
    "\n",
    "#             ax_dat.annotate('',xy=obs_mean-2.5*eig_val[0]*eig_vec[:,0],xytext=obs_mean,\n",
    "#                             arrowprops=dict(arrowstyle='->'))\n",
    "            labels = ['$\\\\bar{q}$','$\\mu_q$']\n",
    "            ax.plot(obs_mean[0],obs_mean[1],'or',label=labels[i])\n",
    "            ax.set_title('Distribution of Heights')\n",
    "            ax.set_xlabel('$y_A$')\n",
    "            ax.set_ylabel('$y_B$')\n",
    "            ax.legend(loc='lower left')\n",
    "\n",
    "# figure name will be \n",
    "this_fig_name = 'fig_intro_problem_types.png'\n",
    "fig_all_master[this_fig_name] = fig_intro_solutions\n",
    "\n",
    "# Save just this fig\n",
    "# fig_intro_solutions.savefig('../'+this_fig_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Solution to Parameter Estimation Problem\n",
    "\n",
    "We have the likelihood of $q$ given $\\vec{\\lambda}$ as multivariate normal with observed mean $\\mu_q$ and known covariance $\\Sigma_q$.\n",
    "\n",
    "The conjugate prior will be a normal distribution. Thus our Bayesian model will be:\n",
    "\n",
    "\\begin{align*}\n",
    "\\vec{\\lambda} &\\sim \\text{mv_normal}(\\mu_0,\\Sigma_0) \\\\\n",
    "Q(\\vec{\\lambda}) &= X\\vec{\\lambda} + y_0 \\quad,\\quad \\text{where } X=\\begin{pmatrix}0.6 & 0.7 \\\\\n",
    "0.8 & 0.6\n",
    "\\end{pmatrix} \\\\\n",
    "q \\mid \\vec{\\lambda} &\\sim \\text{mv_normal}(Q(\\vec{\\lambda}),\\Sigma_q)\n",
    "\\end{align*}\n",
    "\n",
    "Given this model, we can derive the exact posterior distribution for $n$ observations $q_i$ of $q$:\n",
    "\n",
    "\\begin{align*}\n",
    "Q(\\vec{\\lambda}) \\mid q_i &\\sim \\text{mv_normal}(\\mu_{Qpost},\\Sigma_{Qpost}) \\\\\n",
    "\\Sigma_{Qpost} &= \\left( (X\\Sigma_0 X^T)^{-1} + n\\Sigma_q^{-1}\\right)^{-1} \\\\\n",
    "\\mu_{Qpost} &= \\Sigma_{Qpost} \\cdot\\left( (X\\Sigma_0 X^T)^{-1} (X\\mu_0+y_0) + n \\Sigma_q^{-1}\\mu_{q_i} \\right) \\\\\n",
    "\\end{align*}\n",
    "\n",
    "where $\\mu_{q_i}$ is the mean of the observations $q_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, the exact posterior distribution of $\\vec{\\lambda}$ will be:\n",
    "\n",
    "\\begin{align}\n",
    "\\vec{\\lambda} \\mid q_i &\\sim \\text{mv_normal}(\\mu_{post},\\Sigma_{post}) \\\\\n",
    "\\\\\n",
    "\\Sigma_{post} &= (X^{-1})\\Sigma_{Qpost}(X^{-1})^T \\\\\n",
    "& = (X^{-1})\\left[ (X\\Sigma_0 X^T)^{-1} + n\\Sigma_q^{-1}\\right]^{-1}(X^{-1})^T \\\\\n",
    "&= (X)^{-1}\\left[ (X\\Sigma_0 X^T)^{-1} + n\\Sigma_q^{-1}\\right]^{-1}(X^{T})^{-1} \\\\\n",
    "&=\\left[X^{T} \\left( (X\\Sigma_0 X^T)^{-1} + n\\Sigma_q^{-1} \\right) X \\right]^{-1} \\\\\n",
    "&=\\left[X^{T}(X^{T})^{-1}\\Sigma_0^{-1} X^{-1}X + n X^T \\Sigma_q^{-1}X \\right]^{-1}\n",
    "\\\\\n",
    "&=\\left[\\Sigma_0^{-1} + n X^T \\Sigma_q^{-1}X \\right]^{-1}\\\\\n",
    "\\\\\n",
    "\\mu_{post} &= X^{-1}(\\mu_{Qpost}-y_0)\\\\\n",
    "&= X^{-1}\\left[\\Sigma_{Qpost} \\cdot\\left( (X\\Sigma_0 X^T)^{-1} (X\\mu_0+y_0) + n \\Sigma_q^{-1}\\mu_{q_i} \\right)-y_0\\right] \\\\\n",
    "&= X^{-1}\\left[X X^{-1}\\cdot\\Sigma_{Qpost}\\cdot (X^T)^{-1}X^T \\cdot\\left( (X\\Sigma_0 X^T)^{-1} (X\\mu_0+y_0) + n \\Sigma_q^{-1}\\mu_{q_i} \\right)-y_0\\right] \\\\\n",
    "&= X^{-1}\\left[X \\Sigma_{post} X^T \\cdot\\left( (X\\Sigma_0 X^T)^{-1} (X\\mu_0+y_0) + n \\Sigma_q^{-1}\\mu_{q_i} \\right)-y_0\\right] \\\\\n",
    "&= \\left[ \\Sigma_{post} \\cdot\\left( \\Sigma_0^{-1}\\mu_0+ \\Sigma_0^{-1}X^{-1}  y_0 + X^T n \\Sigma_q^{-1}\\mu_{q_i} \\right)-X^{-1}y_0\\right] \\\\\n",
    "&= \\left[ \\Sigma_{post} \\cdot\\left( \\Sigma_0^{-1}\\mu_0 + X^T n \\Sigma_q^{-1}\\mu_{q_i} \\right) + \\Sigma_{post}\\Sigma_0^{-1}X^{-1}  y_0-X^{-1}y_0\\right] \\\\\n",
    "&= \\left[ \\Sigma_{post} \\cdot\\left( \\Sigma_0^{-1}\\mu_0 + X^T n \\Sigma_q^{-1}\\mu_{q_i} \\right) +\\Sigma_{post}\\left(\\Sigma_0^{-1}  -\\Sigma_{post}^{-1}\\right)X^{-1}y_0\\right] \\\\\n",
    "&= \\left[ \\Sigma_{post} \\cdot\\left( \\Sigma_0^{-1}\\mu_0 + X^T n \\Sigma_q^{-1}\\mu_{q_i} \\right) +\\Sigma_{post}\\left(\\Sigma_0^{-1}  -\\Sigma_0^{-1} - X^T n\\Sigma_q^{-1}X\\right)X^{-1}y_0\\right] \\\\\n",
    "&= \\Sigma_{post} \\cdot\\left( \\Sigma_0^{-1}\\mu_0 + n X^T \\Sigma_q^{-1}(\\mu_{q_i}-y_0)\\right)  \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is confirmed in the book by [Kaipio 2005](http://skyline.ucdenver.edu/record=b2382548~S0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantitative Illustration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# propose prior\n",
    "sig0 = EM.sigma0_sphere\n",
    "prior_mean = np.array([0,0]) # centered around the plate's slope being flat\n",
    "prior_cov = sig0*np.eye(2)  # value chosen to be very broad over the space\n",
    "prior_prec = np.linalg.inv(prior_cov)\n",
    "prior_dist = sps.multivariate_normal(prior_mean,prior_cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for plotting\n",
    "prior_sample = prior_dist.rvs(500)\n",
    "Z_prior = prior_dist.pdf(eval_lamXY.T).reshape(lamX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot prior\n",
    "plt.plot(lam_mean[0],lam_mean[1],'or',label='Fixed Slope')\n",
    "plt.scatter(prior_sample.T[0],prior_sample.T[1],label='prior sample',alpha=0.5)\n",
    "plt.contour(lamX,lamY,Z_prior)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Just want to check the relationship between the initial distribution and fixed slope value. The fixed slope value $\\lambda^\\dagger$ is within the support of the initial distribution, which is quite broad by assumption."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check that posterior equations are correct**\n",
    "\n",
    "Here I just validate the derivation equations above computationally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define theoretical posterior distribution\n",
    "\n",
    "# get observed mean and precision\n",
    "# obs_sample_mean = q_obs.mean(axis=0)\n",
    "obs_sample_mean = obs_mean\n",
    "obs_prec = np.linalg.inv(obs_cov)\n",
    "\n",
    "# get posterior covariance\n",
    "post_lam_prec = prior_prec+np.linalg.multi_dot([locations.T,n_obs*obs_prec,locations])\n",
    "post_lam_cov = np.linalg.inv(post_lam_prec)\n",
    "\n",
    "# get push-forward distribution parameters\n",
    "q_prior_mean = np.dot(locations,prior_mean)+y0 ##CHANGE TO Q(mean)\n",
    "q_prior_cov = np.linalg.multi_dot([locations,prior_cov,locations.T])\n",
    "q_prior_prec = np.linalg.inv(q_prior_cov)\n",
    "\n",
    "# get weighted sum for posterior q\n",
    "weighted_mean = np.dot(q_prior_prec,q_prior_mean) + np.dot(n_obs*obs_prec,obs_sample_mean)\n",
    "post_q_cov = np.linalg.multi_dot([locations,post_lam_cov,locations.T])\n",
    "post_q_mean = np.dot(post_q_cov,weighted_mean)\n",
    "\n",
    "# inverse transform to obtain lamda mean\n",
    "post_lam_mean = np.dot(loc_inverse, post_q_mean-y0)\n",
    "\n",
    "# simplified form of posterior mean\n",
    "val = np.linalg.multi_dot([prior_prec,prior_mean])+np.linalg.multi_dot([locations.T,n_obs*obs_prec,obs_sample_mean-y0])\n",
    "post_lam_mean_TEST = np.dot(post_lam_cov,val)\n",
    "\n",
    "# posterior distribution\n",
    "post_dist = sps.multivariate_normal(post_lam_mean,post_lam_cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(post_lam_mean,post_lam_mean_TEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The following plot is just me checking that the method of finding the posterior mean for $q$ and then inverting to obtain the posterior mean for $\\lambda$ is a reasonable appraoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# observed sample\n",
    "plt.contour(qX,qY,Z2)\n",
    "plt.scatter(q_obs.T[0],q_obs.T[1])\n",
    "plt.title('Observed Sample of $n={}$'.format(n_obs))\n",
    "plt.xlabel('$q_A$')\n",
    "plt.ylabel('$q_B$')\n",
    "plt.plot(post_q_mean[0],post_q_mean[1],'or',label='posterior mean for $q$')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain the Posterior for Different Size Samples\n",
    "\n",
    "The goal of this next portion is to obtain the posterior parameters for different sample sizes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obtain the Posterior Parameters**\n",
    "\n",
    "The following function is defined to get the exact posterior parameters using the initial parameters and the observed parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_info = {'prior_mean': prior_mean,\n",
    "             'prior_prec': prior_prec,\n",
    "             'prior_cov': prior_cov,\n",
    "             'linear_map': locations,\n",
    "             'y0': y0,\n",
    "             'obs_prec': obs_prec\n",
    "            }\n",
    "\n",
    "def get_example_posterior_param(sample, info=this_info):\n",
    "    '''\n",
    "    Gets the posterior mean and covariance for this specific example.\n",
    "    prior_info: dictionary of prior_mean, prior_cov, prior_prec, \n",
    "                            linear_map, y0, and known obs_prec\n",
    "    Sample: should be number of samples n x 2x2\n",
    "    returns: posterior mean and posterior covariance\n",
    "    '''\n",
    "    # get info params\n",
    "    this_prior_prec = info['prior_prec']\n",
    "    this_prior_cov = info['prior_cov']\n",
    "    this_prior_mean = info['prior_mean']\n",
    "    \n",
    "    X = info['linear_map']\n",
    "    b = info['y0']\n",
    "    this_obs_prec = info['obs_prec']\n",
    "    \n",
    "    # get sample information\n",
    "    n = sample.shape[0]\n",
    "    sample_mean = sample.mean(axis=0)\n",
    "    \n",
    "    \n",
    "    # get posterior covariance\n",
    "    this_post_prec = this_prior_prec + np.linalg.multi_dot([X.T,n*this_obs_prec,X])\n",
    "    this_post_cov = np.linalg.inv(this_post_prec)\n",
    "\n",
    "    \n",
    "    # get posterior mean\n",
    "    bias_move = np.linalg.multi_dot([this_prior_prec,this_prior_mean]) \n",
    "    data_move = np.linalg.multi_dot([X.T,n*this_obs_prec,sample_mean-b])\n",
    "    this_post_mean = np.dot(this_post_cov,(bias_move+data_move))\n",
    "    \n",
    "    return this_post_mean, this_post_cov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following plot shows how the Bayesian posterior with $n$ samples converges to a fixed point estimate using the likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for plotting\n",
    "Z_post = post_dist.pdf(eval_lamXY.T).reshape(lamX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot posterior\n",
    "plt.plot(lam_mean[0],lam_mean[1],'or',label='Fixed Slope')\n",
    "plt.scatter(prior_sample.T[0],prior_sample.T[1],label='prior sample',alpha=0.5)\n",
    "plt.contour(lamX,lamY,Z_post)\n",
    "# plt.xlim(0,5)\n",
    "# plt.ylim(0,5)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure of Four for Convergence Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make lam-sapce grid\n",
    "lamx_small = np.linspace(0, 2, 100)\n",
    "lamy_small = np.linspace(0, 2, 100)\n",
    "lamX_small, lamY_small = np.meshgrid(lamx_small, lamy_small)\n",
    "eval_lamXY_small = np.vstack([lamX_small.ravel(),lamY_small.ravel()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test = post_dist.rvs(100).T\n",
    "plt.scatter(test[0],test[1])\n",
    "plt.contour(lamX_small,lamY_small,\n",
    "            post_dist.pdf(eval_lamXY_small.T).reshape(lamX_small.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_obs[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_example_posterior_param(q_obs[::100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_param_converge, axes = plt.subplots(2,2)\n",
    "fig_param_converge.set_figheight(8)\n",
    "fig_param_converge.set_figwidth(8)\n",
    "fig_param_converge.tight_layout(h_pad=2)\n",
    "\n",
    "axes = axes.flatten()\n",
    "n_size = [0,1,100,250,q_obs.shape[0]]\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.plot(lam_mean[0],lam_mean[1],'or',label='Fixed Slope')\n",
    "    if i == 0:\n",
    "        Z_prior = prior_dist.pdf(eval_lamXY.T).reshape(lamX.shape)\n",
    "        ax.contour(lamX,lamY,Z_prior)\n",
    "        ax.set_title('Prior')\n",
    "    elif i==1:\n",
    "        this_params = get_example_posterior_param(q_obs[0:n_size[i]])\n",
    "        this_post_pdf = sps.multivariate_normal(this_params[0],this_params[1])\n",
    "        Z_post = this_post_pdf.pdf(eval_lamXY.T).reshape(lamX.shape)\n",
    "        ax.contour(lamX,lamY,Z_post)\n",
    "        ax.set_title('Posterior $n={}$'.format(n_size[i]))\n",
    "    else:\n",
    "        this_params = get_example_posterior_param(q_obs[0:n_size[i]])\n",
    "        this_post_pdf = sps.multivariate_normal(this_params[0],this_params[1])\n",
    "        Z_post = this_post_pdf.pdf(eval_lamXY_small.T).reshape(lamX_small.shape)\n",
    "        ax.contour(lamX_small,lamY_small,Z_post)\n",
    "        ax.set_title('Posterior $n={}$'.format(n_size[i]))\n",
    "\n",
    "# figure name will be \n",
    "this_fig_name = 'bayes_param_converge.png'\n",
    "fig_all_master[this_fig_name] = fig_param_converge\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make the credible region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try and do sampling using uniform along diagonal\n",
    "n_cr = 100\n",
    "# new post\n",
    "mu, sigma = get_example_posterior_param(q_obs[0:n_cr])\n",
    "\n",
    "# posterior\n",
    "post_cred = sps.multivariate_normal(mu,sigma)\n",
    "\n",
    "# to get transformation to uniform along diagonal\n",
    "eig_val, eig_vec = np.linalg.eig(sigma)\n",
    "\n",
    "# sample for integral computation\n",
    "width_dev = 7 # +/- 7 deviations from the mean\n",
    "box_points = sps.uniform.rvs(-width_dev,2*width_dev,size=(100000,2))\n",
    "\n",
    "# transform box points\n",
    "transform_matrix = np.dot(eig_vec,np.sqrt(eig_val)*np.eye(2))\n",
    "transform_box_points = np.dot(transform_matrix,box_points.T).T+mu\n",
    "\n",
    "# area of box points\n",
    "area_box = np.linalg.det(transform_matrix)*(2*width_dev)**2\n",
    "\n",
    "# eval\n",
    "pdf_out = post_cred.pdf(transform_box_points)\n",
    "\n",
    "# make sure sampled area is close to 1\n",
    "print(area_box*np.average(pdf_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization of how I am calculating the area here\n",
    "plt.scatter(transform_box_points[:,0],transform_box_points[:,1])\n",
    "test = post_cred.rvs(1000)\n",
    "plt.scatter(test[:,0],test[:,1])\n",
    "plt.plot(mu[0],mu[1],'ro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get pdf in order of highest likelihood\n",
    "ordered_pdf_out = np.flip(np.sort(pdf_out))\n",
    "\n",
    "# sum terms until we get to probability 95%\n",
    "areas = area_box*np.cumsum(ordered_pdf_out)/pdf_out.shape[0]\n",
    "\n",
    "# get contour value where area reaches 95%\n",
    "C_level = 0.95\n",
    "ind = np.argwhere(areas>C_level)[0]\n",
    "contour_t = ordered_pdf_out[ind]\n",
    "print(contour_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Credible Region**\n",
    "\n",
    "The following region shows the credible region such that the area is 95%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot the 95% credible region\n",
    "fig_credible_region, ax = plt.subplots(1)\n",
    "fig_credible_region.set_figwidth(5)\n",
    "ellipse_lam_dist_95 = make_cov_ellipse(mu,lam_cov,area=0.95,\n",
    "                                       ellipse_args={'color':'r',\n",
    "                                                     'alpha':0.2,'zorder':-1,\n",
    "                                                     'label':'Wobbly-plate Distr.'})\n",
    "ax.add_patch(ellipse_lam_dist_95)\n",
    "region = transform_box_points[pdf_out>contour_t]\n",
    "ax.scatter(region[:,0],region[:,1],label='Bayesian Posterior CR')\n",
    "ax.set_title('{}% credible region $n={}$'.format(int(100*C_level),n_cr))\n",
    "ax.set_xlim(-1,3)\n",
    "ax.set_ylim(-1,3)\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "ax.legend()\n",
    "\n",
    "# save fig to master\n",
    "this_fig_name = 'bayes_param_credible.png'\n",
    "fig_all_master[this_fig_name] = fig_credible_region\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Solution to Parameter Distribution Problem\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(consider page 120 of Kaipio)\n",
    "\n",
    "In the parameter distribution problem, we assume that the plate is wobbling. In this case, it is not errors in our measurement instruments, or additive noise, that is causing the variation in $q$, but variation in sampled values of the slope $\\lambda$.\n",
    "\n",
    "Suppose that we think the distribution of $\\lambda$ is normally distributed with an unknown mean $\\mu$ and unknown variance $\\Sigma$. Our goal is to find the best estimate of the mean and variance and quantify the uncertainty in these parametric estimates of the distribution parameters.\n",
    "\n",
    "We can determine the likelihood function by using a transformation of variables. Given $(\\mu,\\Sigma)$, we know that the distribution of $q$ will be:\n",
    "\n",
    "\\begin{align*}\n",
    "q \\mid \\mu,\\Sigma = \\text{mv_normal}(X\\mu+y_0,X\\Sigma X^T)\n",
    "\\end{align*}\n",
    "\n",
    "We choose a hyperprior for $(\\mu,\\Sigma)$ so that the distribution of $q$ will be normal-inverse-wishart. This will allow us to compute exact solutions for the Bayesian posterior distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our Bayesian model will be:\n",
    "\n",
    "\\begin{align*}\n",
    "\\vec{\\lambda} &\\sim \\mathcal{NIW}(\\mu_0,\\kappa_0,\\nu,\\Psi_0) \\\\\n",
    "Q(\\vec{\\lambda}) &= X\\vec{\\lambda} + y_0 \\quad,\\quad \\text{where } X=\\begin{pmatrix}0.6 & 0.7 \\\\\n",
    "0.8 & 0.6\n",
    "\\end{pmatrix} \\\\\n",
    "q \\mid \\mu,\\Sigma &\\sim \\text{mv_normal}(\\mu_q,\\Sigma_q)\n",
    "\\end{align*}\n",
    "\n",
    "where $\\mu_q=X\\mu +y_0$ and $\\Sigma_q=X\\Sigma X^T$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the distributions of $\\mu_q$ and $\\Sigma_q$:\n",
    "\n",
    "\\begin{align}\n",
    "\\Sigma_q = X\\Sigma X^T &\\sim \\mathcal{IW}(\\nu,X\\Psi_0 X^T) \\\\\n",
    "\\mu_q \\mid \\Sigma_q &\\sim N(X\\mu_0+y_0,\\kappa_0^{-1}\\Sigma_q)\n",
    "\\end{align}\n",
    "\n",
    "This implies that the joint distribution of $(\\mu_q,\\Sigma_q)$ will be normal-inverse-wishart."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here, we can compute the posterior parameters of $(\\mu_q,\\Sigma_q)$ using the standard conjugacy applications.\n",
    "\n",
    "Then we can obtain the hyper-parameters of interest by applying the inverse transformation of variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(q_obs.T[0],q_obs.T[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper-parameters for prior\n",
    "\n",
    "# covariance prior: \n",
    "# we want choose values so that the MAP of the prior is centered around a spherical covariance\n",
    "# recall that the mode of IW is Psi/(nu+p+1)\n",
    "nu = 5 # how much weight to put towards prior\n",
    "Psi_prior = (nu+2+1)*prior_cov # use prior covariance defined earlier\n",
    "\n",
    "# define prior covariance distribution\n",
    "cov_prior_dist = sps.invwishart(nu,Psi_prior)\n",
    "print('Mode of Cov Prior: ', cov_prior_dist.mode())\n",
    "print()\n",
    "\n",
    "# mean prior:\n",
    "# we choose the mean to be 0 (plate is flat)\n",
    "# we want to choose kappa so that the mean is apriori within 2 standard deviations\n",
    "# from the mean\n",
    "mean_prior = np.zeros(2)\n",
    "kappa_prior = 4\n",
    "mean_prior_dist = sps.multivariate_normal(mean_prior,1/kappa_prior*cov_prior_dist.mode())\n",
    "print('Mode (mean) of Prior Mean: ', mean_prior_dist.mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1/q_obs.shape[0]*np.dot((q_obs-q_obs.mean(axis=0)).T,q_obs-q_obs.mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.outer(q_obs.mean(axis=0),q_obs.mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper-parameters for posterior\n",
    "this_info = {'mu0': mean_prior,\n",
    "             'kappa0': kappa_prior,\n",
    "             'nu0': nu,\n",
    "             'Psi0': Psi_prior,\n",
    "             'linear_map': locations,\n",
    "             'y0': y0\n",
    "            }\n",
    "\n",
    "def get_hyper_post_params(sample, info=this_info):\n",
    "    # get prior params\n",
    "    mu0 = info['mu0']\n",
    "    k0 = info['kappa0']\n",
    "    nu0 = info['nu0']\n",
    "    Psi0 = info['Psi0']\n",
    "    \n",
    "    # get map info\n",
    "    X = info['linear_map']\n",
    "    X_inv = np.linalg.inv(X)\n",
    "    y0 = info['y0']\n",
    "    \n",
    "    # get data params\n",
    "    n = sample.shape[0]\n",
    "    qbar = sample.mean(axis=0)\n",
    "    SSq = n*np.cov(sample.T,ddof=0)\n",
    "    \n",
    "    # get lam mean from data\n",
    "    lam_bar = np.dot(X_inv,qbar-y0)\n",
    "    \n",
    "    # mu post\n",
    "    mu_post = (k0*mu0+n*lam_bar)/(k0+n)\n",
    "    \n",
    "    # kappa and nu post\n",
    "    k_post = k0+n\n",
    "    nu_post = nu0+n\n",
    "    \n",
    "    # psi post \n",
    "    # psi: data term\n",
    "    SS_lam = np.linalg.multi_dot([X_inv,SSq,X_inv.T])\n",
    "    \n",
    "    # psi: bias term\n",
    "    bias_term = k0*n/(k0+n)*np.outer(lam_bar-mu0,lam_bar-mu0)\n",
    "    \n",
    "    # combined\n",
    "    psi_post = Psi0 + SS_lam + bias_term \n",
    "    \n",
    "    return mu_post, k_post, nu_post, psi_post\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following figure shows the hierarchical Bayesian model converging to the appropriate target distribution for the Wobbly-plate (as opposed to a point estimate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_dist_converge, axes = plt.subplots(2,2)\n",
    "fig_dist_converge.set_figheight(8)\n",
    "fig_dist_converge.set_figwidth(8)\n",
    "fig_dist_converge.tight_layout(h_pad=2)\n",
    "\n",
    "axes = axes.flatten()\n",
    "n_size = [0,10,100,250,q_obs.shape[0]]\n",
    "for i, ax in enumerate(axes):\n",
    "#     ax.plot(lam_mean[0],lam_mean[1],'or',label='Fixed Slope')\n",
    "    if i == 0:\n",
    "        this_prior_dist = sps.multivariate_normal(mean_prior_dist.mean,cov_prior_dist.mode())\n",
    "        Z_prior = this_prior_dist.pdf(eval_lamXY.T).reshape(lamX.shape)\n",
    "        ax.contour(lamX,lamY,Z_prior)\n",
    "        ax.set_title('Prior')\n",
    "    else:\n",
    "        (mu_p,k_p,nu_p,psi_p) = get_hyper_post_params(q_obs[0:n_size[i]])\n",
    "        sigma_MAP = psi_p/(nu_p+2+1)\n",
    "        mu_MAP = mu_p\n",
    "        this_post_pdf = sps.multivariate_normal(mu_MAP,sigma_MAP)\n",
    "        Z_post = this_post_pdf.pdf(eval_lamXY.T).reshape(lamX.shape)\n",
    "        ax.contour(lamX,lamY,Z_post)\n",
    "        ax.set_title('Distribution of $\\lambda$, $n={}$'.format(n_size[i]))\n",
    "\n",
    "# figure name will be \n",
    "this_fig_name = 'bayes_dist_converge.png'\n",
    "fig_all_master[this_fig_name] = fig_dist_converge\n",
    "\n",
    "# save only this fig\n",
    "# fig_dist_converge.savefig('../'+this_fig_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following figure shows how the hyper-parameters of the Bayesian hierarchical model are converging (to the appropriate point-estimates of the hyper-parameters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_hyper_converge, axes = plt.subplots(2,3)\n",
    "fig_hyper_converge.set_figheight(6)\n",
    "fig_hyper_converge.set_figwidth(8)\n",
    "fig_hyper_converge.tight_layout(h_pad=1.5)\n",
    "\n",
    "n_size = [0,50,250]\n",
    "for j,n in enumerate(n_size):   \n",
    "    # plot the covariance samples\n",
    "    if j==0:\n",
    "        this_cov_sample = cov_prior_dist.rvs(1000)\n",
    "        this_mu_sample = np.array([sps.multivariate_normal.rvs(mean_prior,1/kappa_prior*cov) for cov in this_cov_sample])\n",
    "    else:\n",
    "        (mu_p,k_p,nu_p,psi_p) = get_hyper_post_params(q_obs[0:n])\n",
    "        this_cov_sample = sps.invwishart.rvs(nu_p,psi_p,size=1000)\n",
    "        this_mu_sample = np.array([sps.multivariate_normal.rvs(mu_p,1/k_p*cov) for cov in this_cov_sample])\n",
    "    \n",
    "    # plot the covariances\n",
    "    cov_by_components = np.moveaxis(this_cov_sample,0,-1).reshape((4,-1))\n",
    "    cov_low = np.quantile(cov_by_components,0.01)\n",
    "    cov_high = np.quantile(cov_by_components,0.99)\n",
    "    x = np.linspace(cov_low,cov_high,500)\n",
    "    \n",
    "    label_list = ['$s_{11}$','$s_{12}$','$s_{21}$','$s_{22}$']\n",
    "    for k,comp in enumerate(cov_by_components):\n",
    "        if k==2:\n",
    "            # component 1 and 2 are the same\n",
    "            # because covariance is symmetric\n",
    "            continue       \n",
    "        kde = sps.gaussian_kde(comp)\n",
    "        axes[0,j].plot(x,kde(x),label=label_list[k])\n",
    "        \n",
    "        if j==0:\n",
    "            axes[0,j].set_title('Prior')\n",
    "        else:\n",
    "            axes[0,j].set_title('Post $n={}$'.format(n))\n",
    "        axes[0,j].legend(handlelength=0.9)\n",
    "    \n",
    "    \n",
    "    # plot the means\n",
    "    means_by_components = this_mu_sample.T\n",
    "    mu_low = np.quantile(means_by_components,0.01)\n",
    "    mu_high = np.quantile(means_by_components,0.99)\n",
    "    y = np.linspace(mu_low,mu_high,500)\n",
    "    \n",
    "    for k,comp in enumerate(means_by_components):\n",
    "        kde = sps.gaussian_kde(comp)\n",
    "        axes[1,j].plot(y,kde(y),label='$\\mu_{{ {} }}$'.format(k+1))\n",
    "        \n",
    "        if j==0:\n",
    "            axes[1,j].set_title('Prior')\n",
    "        else:\n",
    "            axes[1,j].set_title('Post $n={}$'.format(n))\n",
    "    axes[1,j].legend(handlelength=0.9)\n",
    "    \n",
    "\n",
    "# annotate axes change\n",
    "for arN in np.arange(2):\n",
    "    adj = -0.05 if arN==0 else 0.15\n",
    "    bbox_props = dict(boxstyle=\"rarrow\", fc=(0.8, 0.9, 0.9), ec=\"b\", lw=2)\n",
    "    t = axes[arN,0].text(1+adj, -0.05, \"     \", ha=\"center\", va=\"top\", rotation=180,\n",
    "                size=10,transform=axes[arN,0].transAxes,\n",
    "                bbox=bbox_props)\n",
    "    bb = t.get_bbox_patch()\n",
    "    bb.set_boxstyle(\"rarrow\", pad=0.15)\n",
    "\n",
    "\n",
    "# axes[0,0].annotate('DETAIL',xy=(150,0.),xycoords='axes points')\n",
    "    \n",
    "# figure name will be \n",
    "this_fig_name = 'bayes_hyper_converge.png'\n",
    "fig_all_master[this_fig_name] = fig_hyper_converge\n",
    "\n",
    "# Save only this fig\n",
    "# fig_hyper_converge.savefig('../'+this_fig_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the same figure as previous, but I re-scale the axes for the presentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_hyper_present_converge, axes = plt.subplots(2,3)\n",
    "fig_hyper_present_converge.set_figheight(6)\n",
    "fig_hyper_present_converge.set_figwidth(8)\n",
    "fig_hyper_present_converge.tight_layout(h_pad=1.5)\n",
    "\n",
    "n_size = [0,50,250]\n",
    "\n",
    "# start by generating the samples\n",
    "saved_samples = {'cov': [], 'mean': []}\n",
    "for j,n in enumerate(n_size):   \n",
    "    # plot the covariance samples\n",
    "    if j==0:\n",
    "        this_cov_sample = cov_prior_dist.rvs(1000)\n",
    "        this_mu_sample = np.array([sps.multivariate_normal.rvs(mean_prior,1/kappa_prior*cov) for cov in this_cov_sample])\n",
    "    else:\n",
    "        (mu_p,k_p,nu_p,psi_p) = get_hyper_post_params(q_obs[0:n])\n",
    "        this_cov_sample = sps.invwishart.rvs(nu_p,psi_p,size=1000)\n",
    "        this_mu_sample = np.array([sps.multivariate_normal.rvs(mu_p,1/k_p*cov) for cov in this_cov_sample])\n",
    "    \n",
    "    # save the samples\n",
    "    saved_samples['cov'].append(this_cov_sample)\n",
    "    saved_samples['mean'].append(this_mu_sample)\n",
    "\n",
    "# get a common lower bound for all covariance plotting\n",
    "cov_all_post = np.moveaxis(np.array(saved_samples['cov'])[1::],[0,1],[-1,-2]).reshape(-1,)\n",
    "cov_low = np.quantile(cov_all_post,0.01)*1.5\n",
    "cov_high = np.quantile(cov_all_post,0.99)*1.65\n",
    "x = np.linspace(cov_low,cov_high,500)\n",
    "\n",
    "mean_all_post = np.array(saved_samples['mean'])[1::].reshape(-1,)\n",
    "mu_low = np.quantile(mean_all_post,0.01)*1.5\n",
    "mu_high = np.quantile(mean_all_post,0.99)*1.5\n",
    "y = np.linspace(mu_low,mu_high,500)\n",
    "\n",
    "for j,n in enumerate(n_size):   \n",
    "    # load the samples\n",
    "    this_cov_sample = saved_samples['cov'][j]\n",
    "    this_mu_sample = saved_samples['mean'][j]\n",
    "    \n",
    "    # plot the covariances\n",
    "    cov_by_components = np.moveaxis(this_cov_sample,0,-1).reshape((4,-1))\n",
    "    \n",
    "    \n",
    "    label_list = ['$s_{11}$','$s_{12}$','$s_{21}$','$s_{22}$']\n",
    "    for k,comp in enumerate(cov_by_components):\n",
    "        if k==2:\n",
    "            # component 1 and 2 are the same\n",
    "            # because covariance is symmetric\n",
    "            continue       \n",
    "        kde = sps.gaussian_kde(comp)\n",
    "        axes[0,j].plot(x,kde(x),label=label_list[k])\n",
    "        \n",
    "        if j==0:\n",
    "            axes[0,j].set_title('Prior')\n",
    "        else:\n",
    "            axes[0,j].set_title('Post $n={}$'.format(n))\n",
    "        axes[0,j].legend(handlelength=0.9)\n",
    "    \n",
    "    \n",
    "    # plot the means\n",
    "    means_by_components = this_mu_sample.T\n",
    "    \n",
    "    for k,comp in enumerate(means_by_components):\n",
    "        kde = sps.gaussian_kde(comp)\n",
    "        axes[1,j].plot(y,kde(y),label='$\\mu_{{ {} }}$'.format(k+1))\n",
    "        \n",
    "        if j==0:\n",
    "            axes[1,j].set_title('Prior')\n",
    "        else:\n",
    "            axes[1,j].set_title('Post $n={}$'.format(n))\n",
    "    axes[1,j].legend(handlelength=0.9)\n",
    "    \n",
    "# change y-scale of axes\n",
    "lower_y = np.array(axes[0,1].get_ylim())/4\n",
    "axes[0,0].set_ylim(lower_y)\n",
    "\n",
    "lower_y = np.array(axes[0,1].get_ylim())/1\n",
    "axes[1,0].set_ylim(lower_y)\n",
    "\n",
    "    \n",
    "    \n",
    "# # annotate axes change\n",
    "# for arN in np.arange(2):\n",
    "#     adj = -0.05 if arN==0 else 0.15\n",
    "#     bbox_props = dict(boxstyle=\"rarrow\", fc=(0.8, 0.9, 0.9), ec=\"b\", lw=2)\n",
    "#     t = axes[arN,0].text(1+adj, -0.05, \"     \", ha=\"center\", va=\"top\", rotation=180,\n",
    "#                 size=10,transform=axes[arN,0].transAxes,\n",
    "#                 bbox=bbox_props)\n",
    "#     bb = t.get_bbox_patch()\n",
    "#     bb.set_boxstyle(\"rarrow\", pad=0.15)\n",
    "\n",
    "\n",
    "# axes[0,0].annotate('DETAIL',xy=(150,0.),xycoords='axes points')\n",
    "    \n",
    "# figure name will be \n",
    "this_fig_name = 'bayes_hyper_present_converge.png'\n",
    "fig_all_master[this_fig_name] = fig_hyper_present_converge\n",
    "\n",
    "# Save only this fig\n",
    "# fig_hyper_present_converge.savefig('../'+this_fig_name,\n",
    "#                                    dpi=250,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes[1,1].get_ylim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.array(saved_samples['cov'])[0:4]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(saved_samples['cov'])[1::,1,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_cov_test[:,:,1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_cov_test = np.moveaxis(np.array(saved_samples['cov'])[1::],[0,1],[-1,-2]).reshape(-1,)\n",
    "print(this_cov_test.shape)\n",
    "np.quantile(this_cov_test,0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in current_axes_lim.keys():\n",
    "    print(item, current_axes_lim[item])\n",
    "    print()\n",
    "    \n",
    "cov_lower_lims = [current_axes_lim['cov'][j][0] for j in [1,2]]\n",
    "print(cov_lower_lims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAVE ALL FIGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure all the figures are there\n",
    "for key in fig_all_master.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check individual figures\n",
    "check_name = None\n",
    "if check_name == None:\n",
    "    print()\n",
    "else:\n",
    "    fig_all_master[check_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # save all figs\n",
    "# for figfilename in fig_all_master:\n",
    "#     fig_all_master[figfilename].savefig('../'+figfilename,\n",
    "#                                         dpi=250,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
