{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports necessary Packages\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "\n",
    "# Specific Plotting Packages\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib import patches\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# Specific Stats Packages\n",
    "from scipy.stats import gaussian_kde\n",
    "from scipy.stats import truncexpon\n",
    "from scipy.stats import uniform\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import chi2\n",
    "from scipy.stats import normaltest\n",
    "from scipy.stats import multivariate_normal as mv_norm\n",
    "\n",
    "# for showing youtube videos\n",
    "from IPython.display import YouTubeVideo\n",
    "\n",
    "# for Q map\n",
    "from scipy import optimize\n",
    "\n",
    "# to show in notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a random seed\n",
    "np.random.seed(24513)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams.update({'font.size': 14})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defines a general color pallette\n",
    "col_highlight = 'xkcd:yellow'\n",
    "col_blue = 'xkcd:sky'\n",
    "col_red = 'xkcd:red orange'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Wobbly Plate Example\n",
    "\n",
    "In this example we have a linear system of equations affected by different noise models. The idea is that we have two sensors which measure the height of the plate and we are trying to determine the variation of the slopes of the wobbly plate. We solve this problem using Data-consistent inversion (see the dissertation for details).\n",
    "\n",
    "Specifically, the model is:\n",
    "\n",
    "\\begin{align}\n",
    "q=Q(\\lambda)=X\\lambda + y_0\n",
    "\\end{align}\n",
    "\n",
    "where $X$ is a matrix of the locations of the measurement instruments, $y_0$ is the height of the plate above the origin, and $\\lambda$ is the slope of the wobbly plate.\n",
    "\n",
    "We are insterested in investigating the case where this system is perturbed by additional stochastic uncertainties. Specifically, we look at the differences between an additive versus a location noise model.\n",
    "\n",
    "In the additive noise model, we have that:\n",
    "\n",
    "\\begin{align}\n",
    "q=\\widehat{Q}(\\lambda,\\xi)=Q(\\lambda)+\\xi= (X\\lambda + y_0)+\\xi\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "On the other hand, in a location noise model, we have that:\n",
    "\n",
    "\\begin{align}\n",
    "q=\\widehat{Q}(\\lambda,\\xi)= (X+\\xi)\\lambda + y_0)\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "As shown in this notebook, this can lead to very different results because $\\lambda$ scales the noise parameter $\\xi$ in the location noise model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defines Model Map\n",
    "\n",
    "> You can adjust whether map produces additive or location noise by setting corresponding option to True or False. Also, you can pass a custom pdf as long as it is a scipy stats-like class with corresponding pdf and rvs calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our model map\n",
    "def Y(beta,x, height=3, \n",
    "      additive_noise=False, add_noise_pdf=norm(0,0.15), \n",
    "      location_noise=False, loc_noise_pdf=norm(0,0.15)):\n",
    "    \n",
    "    '''\n",
    "    beta: matrix of coefficients, each row a separate observation\n",
    "    x: location vector of measurements OR matrix. If matrix, must be the same size as beta\n",
    "    height: fixed height of the center of the wobbly plate\n",
    "    addiive_noise: is there additive noise?\n",
    "    add_noise_pdf: scipy stats class specificying the additive noise model\n",
    "    location_noise: is there location noise?\n",
    "    loc_noise_pdf: scipy stats class specifying location noise model\n",
    "    '''\n",
    "    \n",
    "    y0 = height # fixed height\n",
    "    \n",
    "    if beta.shape != x.shape:\n",
    "        # reshape x-array to be same size as beta\n",
    "        columns = np.shape(beta)[0]\n",
    "        x_values = np.repeat(x,columns).reshape(np.shape(x)[0],columns).transpose()\n",
    "    else:\n",
    "        x_values = x\n",
    "    \n",
    "    if location_noise:\n",
    "        x_values = x_values+loc_noise_pdf.rvs(x_values.shape)\n",
    "    \n",
    "    \n",
    "    y_output = y0+np.sum(beta*x_values,axis=1)\n",
    "    \n",
    "    # add additive noise\n",
    "    if additive_noise:\n",
    "        y_output = y_output+add_noise_pdf.rvs(y_output.shape)\n",
    "    \n",
    "    return y_output, x_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No Noise Example\n",
    "\n",
    "Here we look at a scenario where there is no additive or location noise.\n",
    "\n",
    "What does the solution to the wobbly-plate problem look like using Data-consistent inversion?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_obs = 250 # number of observations\n",
    "locations = np.array([[0.6,0.6],[0.8,0.6]]) # location of observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Use `lower_a1` and `lower_a2` to set the domain $\\Lambda$. These two parameters set the center of the rectangular bounding box (set at the origin, $\\Lambda$ is $[0,2]\\times[0,2]$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# location params for true parameter distribution: center at\n",
    "lower_a1 = 1\n",
    "lower_a2 = 1\n",
    "\n",
    "# beta values at each observation point\n",
    "beta1_data = uniform.rvs(lower_a1-0.15,0.6,n_obs)\n",
    "beta2_data = uniform.rvs(lower_a2+0.6,0.25,n_obs)\n",
    "\n",
    "beta_data = np.stack((beta1_data,beta2_data),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plots of Initial Description vs. Target PDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope_fig, ax = plt.subplots(1)\n",
    "# set up prior range of slopes\n",
    "bounding_range = np.linspace(lower_a1-1,lower_a1+1,100)\n",
    "plt.plot(bounding_range,np.max(bounding_range)*np.ones(100),color=col_blue,ls='--',linewidth=2,label='Initial Description of Slopes') # top\n",
    "plt.plot(np.max(bounding_range)*np.ones(100),bounding_range,color=col_blue,ls='--',linewidth=2) # right\n",
    "plt.plot(bounding_range,np.min(bounding_range)*np.ones(100),color=col_blue,ls='--',linewidth=2) # bottom\n",
    "plt.plot(np.min(bounding_range)*np.ones(100),bounding_range,color=col_blue,ls='--',linewidth=2) # left\n",
    "plt.title('Parameter Space: Slope of Plate')\n",
    "plt.xlabel('$\\lambda_1$')\n",
    "plt.ylabel('$\\lambda_2$')\n",
    "\n",
    "# scatter plot of slopes\n",
    "#plt.scatter(beta1_data,beta2_data,label=\"Target Sampled Distribution\")\n",
    "#plt.scatter(beta_Q_inv[0],beta_Q_inv[1])\n",
    "\n",
    "# plot actual pdf of slopes\n",
    "slope_pdf_plot = patches.Rectangle((lower_a1-0.15,lower_a2+0.6),0.6,0.25,\n",
    "                                   label=\"Target Distribution\",\n",
    "                                   edgecolor='k',facecolor=col_highlight,alpha=1)\n",
    "ax.add_patch(slope_pdf_plot)\n",
    "\n",
    "plt.xlim(lower_a1-1.2,lower_a1+1.2)\n",
    "plt.ylim(lower_a2-1.2,lower_a2+1.2)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#slope_fig.savefig('wobbly-target.png',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulated QoI data from data variable samples\n",
    "# NO NOISE\n",
    "y_data_loc1,loc1 = Y(beta_data,locations[0],location_noise=False)\n",
    "y_data_loc2,loc2 = Y(beta_data,locations[1],location_noise=False)\n",
    "y_data = np.array([y_data_loc1,y_data_loc2])\n",
    "\n",
    "# calculate a gaussian kde for data\n",
    "data_kde_pdf = gaussian_kde(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(4,6,100)\n",
    "data_fig = plt.figure()\n",
    "plt.title('GKDE Distribution of Sampled Height Data')\n",
    "plt.plot(x,gaussian_kde(y_data_loc1)(x),label='Obs. at Loc A',\n",
    "         ls='--',linewidth=2.25,color='xkcd:sky')\n",
    "plt.plot(x,gaussian_kde(y_data_loc2)(x),label='Obs. at Loc B',\n",
    "         ls=':',linewidth=3, color='xkcd:red orange')\n",
    "plt.ylabel('Relative Frequency')\n",
    "plt.xlabel('Height, $y$')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_fig.savefig('wobbly-data.png',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Consistent Inversion:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate initial samples\n",
    "beta1_initial = uniform(lower_a1-1,2)\n",
    "beta2_initial = uniform(lower_a2-1,2)\n",
    "\n",
    "# number of samples for approximating push-forward\n",
    "n_samples = 4000\n",
    "\n",
    "# generate a sample from our INITIAL pdfs\n",
    "beta1_sample_initial = beta1_initial.rvs(n_samples)\n",
    "beta2_sample_initial = beta2_initial.rvs(n_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defines initial distribution class objects using scipy package (imported at the top)\n",
    "# use \"rvs\" method to generate samples from these objects\n",
    "# use \"pdf\" method to evaluate the pdf at a given value\n",
    "\n",
    "# combine into a matrix of observations\n",
    "beta_initial = np.stack((beta1_sample_initial,beta2_sample_initial),axis=1)\n",
    "\n",
    "# calculate data values\n",
    "y_push_forward = np.array([ Y(beta_initial,locations[0])[0], \n",
    "                            Y(beta_initial,locations[1])[0]])\n",
    "\n",
    "# calculate a gaussian kde for the push-forward of the sampled inital values\n",
    "push_forward_kde_pdf = gaussian_kde(y_push_forward)\n",
    "\n",
    "\n",
    "# calculate maximum of the ratio\n",
    "M = np.max(data_kde_pdf(y_push_forward)/push_forward_kde_pdf(y_push_forward))\n",
    "\n",
    "# generate random numbers from uniform for accept-reject for each sample value\n",
    "test_value = np.random.uniform(0,1,n_samples)\n",
    "\n",
    "# calculate the ratio for accept reject: data_kde/push_kde/M and compare to test sample\n",
    "# is the kde ratio > test value?\n",
    "accept_or_reject_samples = np.greater(data_kde_pdf(y_push_forward)/push_forward_kde_pdf(y_push_forward)/M,\n",
    "                            test_value)\n",
    "\n",
    "# accepted values of posterior sample\n",
    "updated_beta1_sample = beta1_sample_initial[accept_or_reject_samples]\n",
    "updated_beta2_sample = beta2_sample_initial[accept_or_reject_samples]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accept_or_reject_samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_fig, ax = plt.subplots(1)\n",
    "# plot actual pdf of slopes\n",
    "target_pdf_plot = patches.Rectangle((lower_a1-0.15,lower_a2+0.6),0.6,0.25,\n",
    "                                   label=\"Target Sample\",\n",
    "                                   edgecolor='xkcd:yellow',facecolor='C2',alpha=1,\n",
    "                                   zorder=2,fill=False,linewidth=3.5)\n",
    "ax.add_patch(target_pdf_plot)\n",
    "plt.scatter(beta1_sample_initial,beta2_sample_initial,marker='o',zorder=0,\n",
    "            color='xkcd:sky',alpha=1, label='Initial Sample')\n",
    "plt.scatter(updated_beta1_sample,updated_beta2_sample,\n",
    "            marker='x',s=140,\n",
    "            color='xkcd:red orange',edgecolor='k',zorder=1,alpha=1,\n",
    "            label='Update Sample')\n",
    "plt.legend()\n",
    "plt.title('Data Consistent Update')\n",
    "plt.xlabel('$\\lambda_1$')\n",
    "plt.ylabel('$\\lambda_2$')\n",
    "\n",
    "# direct inversion using Q^-1 just for testing\n",
    "# lam_inverted = np.dot(np.linalg.inv(locations),y_data-3)\n",
    "# ax.scatter(lam_inverted[0],lam_inverted[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update_fig.savefig('wobbly-update.png',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check grayscale compatability\n",
    "# fname = 'wobbly-update.png'\n",
    "# image = Image.open(fname).convert(\"L\")\n",
    "# arr = np.asarray(image)\n",
    "# plt.imshow(arr, cmap='gray', vmin=0, vmax=255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additive Noise Data\n",
    "\n",
    "Here we investigate the same setup with the additive noise model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulated QoI data from data variable samples\n",
    "# ADDITIVE NOISE\n",
    "y_data_loc1,loc1 = Y(beta_data,locations[0],additive_noise=True)\n",
    "y_data_loc2,loc2 = Y(beta_data,locations[1],additive_noise=True)\n",
    "y_data = np.array([y_data_loc1,y_data_loc2])\n",
    "\n",
    "# calculate a gaussian kde for data\n",
    "data_kde_pdf = gaussian_kde(y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Consistent Inversion:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate initial samples\n",
    "beta1_initial = uniform(lower_a1-1,2)\n",
    "beta2_initial = uniform(lower_a2-1,2)\n",
    "\n",
    "# number of samples for approximating push-forward\n",
    "n_samples = 4000\n",
    "\n",
    "# generate a sample from our INITIAL pdfs\n",
    "beta1_sample_initial = beta1_initial.rvs(n_samples)\n",
    "beta2_sample_initial = beta2_initial.rvs(n_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defines initial distribution class objects using scipy package (imported at the top)\n",
    "# use \"rvs\" method to generate samples from these objects\n",
    "# use \"pdf\" method to evaluate the pdf at a given value\n",
    "\n",
    "# combine into a matrix of observations\n",
    "beta_initial = np.stack((beta1_sample_initial,beta2_sample_initial),axis=1)\n",
    "\n",
    "# calculate data values\n",
    "y_push_forward = np.array([ Y(beta_initial,locations[0],additive_noise=True)[0], \n",
    "                            Y(beta_initial,locations[1],additive_noise=True)[0]])\n",
    "\n",
    "# calculate a gaussian kde for the push-forward of the sampled inital values\n",
    "push_forward_kde_pdf = gaussian_kde(y_push_forward)\n",
    "\n",
    "\n",
    "# calculate maximum of the ratio\n",
    "M = np.max(data_kde_pdf(y_push_forward)/push_forward_kde_pdf(y_push_forward))\n",
    "\n",
    "# generate random numbers from uniform for accept-reject for each sample value\n",
    "test_value = np.random.uniform(0,1,n_samples)\n",
    "\n",
    "# calculate the ratio for accept reject: data_kde/push_kde/M and compare to test sample\n",
    "# is the kde ratio > test value?\n",
    "accept_or_reject_samples = np.greater(data_kde_pdf(y_push_forward)/push_forward_kde_pdf(y_push_forward)/M,\n",
    "                            test_value)\n",
    "\n",
    "# accepted values of posterior sample\n",
    "updated_beta1_sample = beta1_sample_initial[accept_or_reject_samples]\n",
    "updated_beta2_sample = beta2_sample_initial[accept_or_reject_samples]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_fig_noise, ax = plt.subplots(1)\n",
    "# plot actual pdf of slopes\n",
    "target_pdf_plot = patches.Rectangle((lower_a1-0.15,lower_a2+0.6),0.6,0.25,\n",
    "                                   label=\"Target Sample\",\n",
    "                                   edgecolor='xkcd:yellow',facecolor='C2',alpha=1,\n",
    "                                   zorder=2,fill=False,linewidth=3.5)\n",
    "ax.add_patch(target_pdf_plot)\n",
    "plt.scatter(beta1_sample_initial,beta2_sample_initial,marker='o',zorder=0,\n",
    "            color='xkcd:sky',alpha=1, label='Initial Sample')\n",
    "plt.scatter(updated_beta1_sample,updated_beta2_sample,\n",
    "            marker='x',s=140,\n",
    "            color='xkcd:red orange',edgecolor='k',zorder=1,alpha=1,\n",
    "            label='Update Sample')\n",
    "plt.legend()\n",
    "plt.title('Data Consistent Update')\n",
    "plt.xlabel('$\\lambda_1$')\n",
    "plt.ylabel('$\\lambda_2$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update_fig_noise.savefig('wobbly-update-noise.png',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Location Uncertainty Data\n",
    "\n",
    "Here we solve the same problem using the location noise model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulated QoI data from data variable samples\n",
    "loc_noise_std = 0.05\n",
    "y_data_loc1,loc1 = Y(beta_data,locations[0],location_noise=True,loc_noise_pdf=norm(0,loc_noise_std))\n",
    "y_data_loc2,loc2 = Y(beta_data,locations[1],location_noise=True,loc_noise_pdf=norm(0,loc_noise_std))\n",
    "y_data = np.array([y_data_loc1,y_data_loc2])\n",
    "\n",
    "# calculate a gaussian kde for data\n",
    "data_kde_pdf = gaussian_kde(y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plots of the Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# location distribution\n",
    "# plots x_data\n",
    "loc_fig, ax1 = plt.subplots()\n",
    "ax1.scatter(loc1[:,0],loc1[:,1],label='actual locations $\\\\bf{x_A}$',\n",
    "            color=col_blue,marker='x',s=150)\n",
    "ax1.scatter(loc2[:,0],loc2[:,1], label='actual locations $\\\\bf{x_B}$',\n",
    "            color=col_red,marker='+',s=150)\n",
    "#ax1.add_patch(patches.Rectangle((-1,-1),2.3,2.3,linewidth=1,edgecolor='gray',facecolor='none',ls='--'))\n",
    "ax1.set_xlim([-.4,1.4])\n",
    "ax1.set_ylim([-.4,1.4])\n",
    "ax1.set_title(\"Unobserved Measurement Location Variation\")\n",
    "ax1.plot(locations[:,0],locations[:,1],'*',color=col_highlight,label='specified locations',markersize=14,markeredgecolor='k')\n",
    "ax1.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loc_fig.savefig('wobbly-plate-loc-noise.png',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height_fig_locnoise = plt.figure()\n",
    "x = np.linspace(4,6,100)\n",
    "plt.title('GKDE Distribution of Sampled Height Data')\n",
    "plt.plot(x,gaussian_kde(y_data_loc1)(x),label='Obs. at Loc A',\n",
    "         ls='--',linewidth=2.25,color='xkcd:sky')\n",
    "plt.plot(x,gaussian_kde(y_data_loc2)(x),label='Obs. at Loc B',\n",
    "         ls=':',linewidth=3, color='xkcd:red orange')\n",
    "# plt.hist(y_data_loc1,edgecolor='k',label=\"Obs. at Loc A\",alpha=0.8)\n",
    "# plt.hist(y_data_loc2,edgecolor='k',label=\"Obs. at Loc B\",alpha=0.5)\n",
    "plt.xlabel('Height, $y$')\n",
    "plt.ylabel('Relative Frequency')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# height_fig_locnoise.savefig('wobbly-plate-loc-data.png',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Direct Inversion using $Q^{-1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lam_inverted = np.dot(np.linalg.inv(locations),y_data-3)\n",
    "plt.scatter(lam_inverted[0],lam_inverted[1])\n",
    "plt.xlim(0,2)\n",
    "plt.ylim(0,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial Samples for Data Consistent Inversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate initial samples\n",
    "beta1_initial = uniform(lower_a1-1,2)\n",
    "beta2_initial = uniform(lower_a2-1,2)\n",
    "\n",
    "# number of samples for approximating push-forward\n",
    "n_samples = 4000\n",
    "\n",
    "# generate a sample from our INITIAL pdfs\n",
    "beta1_sample_initial = beta1_initial.rvs(n_samples)\n",
    "beta2_sample_initial = beta2_initial.rvs(n_samples)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computed with Additive Noise Modeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defines initial distribution class objects using scipy package (imported at the top)\n",
    "# use \"rvs\" method to generate samples from these objects\n",
    "# use \"pdf\" method to evaluate the pdf at a given value\n",
    "\n",
    "# combine into a matrix of observations\n",
    "beta_initial = np.stack((beta1_sample_initial,beta2_sample_initial),axis=1)\n",
    "\n",
    "# calculate data values\n",
    "y_push_forward = np.array([ Y(beta_initial,locations[0],additive_noise=True)[0], \n",
    "                            Y(beta_initial,locations[1],additive_noise=True)[0]])\n",
    "\n",
    "# calculate a gaussian kde for the push-forward of the sampled inital values\n",
    "push_forward_kde_pdf = gaussian_kde(y_push_forward)\n",
    "\n",
    "\n",
    "# calculate maximum of the ratio\n",
    "M = np.max(data_kde_pdf(y_push_forward)/push_forward_kde_pdf(y_push_forward))\n",
    "\n",
    "# generate random numbers from uniform for accept-reject for each sample value\n",
    "test_value = np.random.uniform(0,1,n_samples)\n",
    "\n",
    "# calculate the ratio for accept reject: data_kde/push_kde/M and compare to test sample\n",
    "# is the kde ratio > test value?\n",
    "accept_or_reject_samples = np.greater(data_kde_pdf(y_push_forward)/push_forward_kde_pdf(y_push_forward)/M,\n",
    "                            test_value)\n",
    "\n",
    "# accepted values of posterior sample\n",
    "updated_beta1_sample = beta1_sample_initial[accept_or_reject_samples]\n",
    "updated_beta2_sample = beta2_sample_initial[accept_or_reject_samples]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "update_fig_ADD, ax = plt.subplots(1)\n",
    "# target distribution\n",
    "target_pdf_plot = patches.Rectangle((lower_a1-0.15,lower_a2+0.6),0.6,0.25,\n",
    "                                   label=\"Target Sample\",\n",
    "                                   edgecolor='xkcd:yellow',facecolor='C2',alpha=1,\n",
    "                                   zorder=2,fill=False,linewidth=3.5)\n",
    "ax.add_patch(target_pdf_plot)\n",
    "\n",
    "plt.scatter(beta1_sample_initial, beta2_sample_initial,\n",
    "            label='Initial Sample',marker='o',zorder=0,\n",
    "            color='xkcd:sky',alpha=1)\n",
    "\n",
    "plt.scatter(updated_beta1_sample,updated_beta2_sample,\n",
    "            marker='x',s=140,\n",
    "            color='xkcd:red orange',edgecolor='k',zorder=1,alpha=1,\n",
    "            label='Update Sample')\n",
    "\n",
    "plt.xlabel('$\\lambda_1$')\n",
    "plt.ylabel('$\\lambda_2$')\n",
    "plt.title('Data Consistent Update')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update_fig_ADD.savefig('wobbly-update-loc-noise-wrong-model.png',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computed with Location Noise Modeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defines initial distribution class objects using scipy package (imported at the top)\n",
    "# use \"rvs\" method to generate samples from these objects\n",
    "# use \"pdf\" method to evaluate the pdf at a given value\n",
    "# combine into a matrix of observations\n",
    "beta_initial = np.stack((beta1_sample_initial,beta2_sample_initial),axis=1)\n",
    "\n",
    "# calculate data values\n",
    "y_push_forward_LOC = np.array([ Y(beta_initial,locations[0],location_noise=True)[0], \n",
    "                            Y(beta_initial,locations[1],location_noise=True)[0]])\n",
    "\n",
    "# calculate a gaussian kde for the push-forward of the sampled inital values\n",
    "push_forward_kde_pdf_LOC = gaussian_kde(y_push_forward_LOC)\n",
    "\n",
    "\n",
    "# calculate maximum of the ratio\n",
    "M = np.max(data_kde_pdf(y_push_forward_LOC)/push_forward_kde_pdf_LOC(y_push_forward_LOC))\n",
    "\n",
    "# generate random numbers from uniform for accept-reject for each sample value\n",
    "test_value = np.random.uniform(0,1,n_samples)\n",
    "\n",
    "# calculate the ratio for accept reject: data_kde/push_kde/M and compare to test sample\n",
    "# is the kde ratio > test value?\n",
    "accept_or_reject_samples_LOC = np.greater(data_kde_pdf(y_push_forward_LOC)/push_forward_kde_pdf_LOC(y_push_forward_LOC)/M,\n",
    "                            test_value)\n",
    "\n",
    "# accepted values of posterior sample\n",
    "updated_beta1_sample_LOC = beta1_sample_initial[accept_or_reject_samples_LOC]\n",
    "updated_beta2_sample_LOC = beta2_sample_initial[accept_or_reject_samples_LOC]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_fig_LOC, ax = plt.subplots(1)\n",
    "\n",
    "# target distribution\n",
    "target_pdf_plot = patches.Rectangle((lower_a1-0.15,lower_a2+0.6),0.6,0.25,\n",
    "                                   label=\"Target Sample\",\n",
    "                                   edgecolor='xkcd:yellow',facecolor='C2',alpha=1,\n",
    "                                   zorder=2,fill=False,linewidth=3.5)\n",
    "ax.add_patch(target_pdf_plot)\n",
    "\n",
    "plt.scatter(beta1_sample_initial, beta2_sample_initial,marker='o',zorder=0,\n",
    "            color='xkcd:sky',alpha=1, label='Update Sample')\n",
    "plt.scatter(updated_beta1_sample_LOC,updated_beta2_sample_LOC,\n",
    "            marker='x',s=140,\n",
    "            color='xkcd:red orange',edgecolor='k',zorder=1,alpha=1,\n",
    "            label='Update Sample')\n",
    "\n",
    "#plt.xlim(-1.2,1.2)\n",
    "#plt.ylim(-1.2,1.2)\n",
    "\n",
    "plt.xlabel('$\\lambda_1$')\n",
    "plt.ylabel('$\\lambda_2$')\n",
    "plt.title('Data Consistent Update')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update_fig_LOC.savefig('wobbly-update-loc-noise-correct-model.png',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check predictability assumption\n",
    "print(\"For Additive Model: \", np.mean(data_kde_pdf(y_push_forward)/push_forward_kde_pdf(y_push_forward)))\n",
    "print()\n",
    "print(\"For Loc Model: \", np.mean(data_kde_pdf(y_push_forward_LOC)/push_forward_kde_pdf_LOC(y_push_forward_LOC)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Location Uncertainty Model with Domain Shift\n",
    "\n",
    "Here we shift the initial domain to be $[0,2]$. This will illustrate the differences between location and additive noise models better because the slopes $\\lambda$ of the wobbly-plate will scale the location noise more extremely than when we're within the domain $\\Lambda:=[0,1]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# location params for true parameter distribution: center at\n",
    "lower_a1 = 1\n",
    "lower_a2 = 1\n",
    "\n",
    "# beta values at each observation point\n",
    "beta1_data = uniform.rvs(lower_a1-0.15,0.6,n_obs)\n",
    "beta2_data = uniform.rvs(lower_a2+0.6,0.25,n_obs)\n",
    "\n",
    "beta_data = np.stack((beta1_data,beta2_data),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulated QoI data from data variable samples\n",
    "loc_noise_std = 0.075\n",
    "y_data_loc1,loc1 = Y(beta_data,locations[0],location_noise=True,loc_noise_pdf=norm(0,loc_noise_std))\n",
    "y_data_loc2,loc2 = Y(beta_data,locations[1],location_noise=True,loc_noise_pdf=norm(0,loc_noise_std))\n",
    "y_data = np.array([y_data_loc1,y_data_loc2])\n",
    "\n",
    "# calculate a gaussian kde for data\n",
    "data_kde_pdf = gaussian_kde(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope_fig_shift, ax = plt.subplots(1)\n",
    "# set up prior range of slopes\n",
    "bounding_range = np.linspace(lower_a1-1,lower_a1+1,100)\n",
    "plt.plot(bounding_range,np.max(bounding_range)*np.ones(100),color=col_blue,ls='--',linewidth=2,label='Initial Description of Slopes') # top\n",
    "plt.plot(np.max(bounding_range)*np.ones(100),bounding_range,color=col_blue,ls='--',linewidth=2) # right\n",
    "plt.plot(bounding_range,np.min(bounding_range)*np.ones(100),color=col_blue,ls='--',linewidth=2) # bottom\n",
    "plt.plot(np.min(bounding_range)*np.ones(100),bounding_range,color=col_blue,ls='--',linewidth=2) # left\n",
    "plt.title('Parameter Space: Slope of Plate')\n",
    "plt.xlabel('$\\lambda_1$')\n",
    "plt.ylabel('$\\lambda_2$')\n",
    "\n",
    "# scatter plot of slopes\n",
    "#plt.scatter(beta1_data,beta2_data,label=\"Target Sampled Distribution\")\n",
    "#plt.scatter(beta_Q_inv[0],beta_Q_inv[1])\n",
    "\n",
    "# plot actual pdf of slopes\n",
    "slope_pdf_plot = patches.Rectangle((lower_a1-0.15,lower_a2+0.6),0.6,0.25,\n",
    "                                   label=\"Target Distribution\",\n",
    "                                   edgecolor='k',facecolor=col_highlight,alpha=1)\n",
    "ax.add_patch(slope_pdf_plot)\n",
    "\n",
    "plt.xlim(lower_a1-1.2,lower_a1+1.2)\n",
    "plt.ylim(lower_a2-1.2,lower_a2+1.2)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plots of the Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# location distribution\n",
    "# plots x_data\n",
    "loc_fig_shift, ax1 = plt.subplots()\n",
    "ax1.scatter(loc1[:,0],loc1[:,1],label='actual locations $\\\\bf{x_A}$',\n",
    "            color=col_blue,marker='x',s=150)\n",
    "ax1.scatter(loc2[:,0],loc2[:,1], label='actual locations $\\\\bf{x_B}$',\n",
    "            color=col_red,marker='+',s=150)\n",
    "#ax1.add_patch(patches.Rectangle((-1,-1),2.3,2.3,linewidth=1,edgecolor='gray',facecolor='none',ls='--'))\n",
    "ax1.set_xlim([-.4,1.4])\n",
    "ax1.set_ylim([-.4,1.4])\n",
    "ax1.set_title(\"Unobserved Measurement Location Variation\")\n",
    "ax1.plot(locations[:,0],locations[:,1],'*',color=col_highlight,label='specified locations',markersize=14,markeredgecolor='k')\n",
    "ax1.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height_fig_locnoise_shift = plt.figure()\n",
    "x = np.linspace(3,6,100)\n",
    "plt.title('GKDE Distribution of Sampled Height Data')\n",
    "plt.plot(x,gaussian_kde(y_data_loc1)(x),label='Obs. at Loc A',\n",
    "         ls='--',linewidth=2.25,color='xkcd:sky')\n",
    "plt.plot(x,gaussian_kde(y_data_loc2)(x),label='Obs. at Loc B',\n",
    "         ls=':',linewidth=3, color='xkcd:red orange')\n",
    "# plt.hist(y_data_loc1,edgecolor='k',label=\"Obs. at Loc A\",alpha=0.8)\n",
    "# plt.hist(y_data_loc2,edgecolor='k',label=\"Obs. at Loc B\",alpha=0.5)\n",
    "plt.xlabel('Height, $y$')\n",
    "plt.ylabel('Relative Frequency')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial Samples for Data Consistent Inversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate initial samples\n",
    "beta1_initial = uniform(lower_a1-1,2)\n",
    "beta2_initial = uniform(lower_a2-1,2)\n",
    "\n",
    "# number of samples for approximating push-forward\n",
    "n_samples = 3500\n",
    "\n",
    "# generate a sample from our INITIAL pdfs\n",
    "beta1_sample_initial = beta1_initial.rvs(n_samples)\n",
    "beta2_sample_initial = beta2_initial.rvs(n_samples)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computed with Additive Noise Modeled\n",
    "\n",
    "This shows what happens when we use the wrong model to compute the update.\n",
    "\n",
    "Here, the additive noise model doesn't satisfy the predictability assumption (due to lack of scaling of the location noise)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defines initial distribution class objects using scipy package (imported at the top)\n",
    "# use \"rvs\" method to generate samples from these objects\n",
    "# use \"pdf\" method to evaluate the pdf at a given value\n",
    "\n",
    "# combine into a matrix of observations\n",
    "beta_initial = np.stack((beta1_sample_initial,beta2_sample_initial),axis=1)\n",
    "\n",
    "# calculate data values\n",
    "add_sig = loc_noise_std*1.1\n",
    "y_push_forward = np.array([ Y(beta_initial,locations[0],additive_noise=True,add_noise_pdf=norm(0,add_sig))[0], \n",
    "                            Y(beta_initial,locations[1],additive_noise=True,add_noise_pdf=norm(0,add_sig))[0]])\n",
    "\n",
    "# calculate a gaussian kde for the push-forward of the sampled inital values\n",
    "push_forward_kde_pdf = gaussian_kde(y_push_forward)\n",
    "\n",
    "\n",
    "# calculate maximum of the ratio\n",
    "M = np.max(data_kde_pdf(y_push_forward)/push_forward_kde_pdf(y_push_forward))\n",
    "\n",
    "# generate random numbers from uniform for accept-reject for each sample value\n",
    "test_value = np.random.uniform(0,1,n_samples)\n",
    "\n",
    "# calculate the ratio for accept reject: data_kde/push_kde/M and compare to test sample\n",
    "# is the kde ratio > test value?\n",
    "accept_or_reject_samples = np.greater(data_kde_pdf(y_push_forward)/push_forward_kde_pdf(y_push_forward)/M,\n",
    "                            test_value)\n",
    "\n",
    "# accepted values of posterior sample\n",
    "updated_beta1_sample = beta1_sample_initial[accept_or_reject_samples]\n",
    "updated_beta2_sample = beta2_sample_initial[accept_or_reject_samples]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "update_fig_ADD_shift, ax = plt.subplots(1)\n",
    "# target distribution\n",
    "target_pdf_plot = patches.Rectangle((lower_a1-0.15,lower_a2+0.6),0.6,0.25,\n",
    "                                   label=\"Target Sample\",\n",
    "                                   edgecolor='xkcd:yellow',facecolor='C2',alpha=1,\n",
    "                                   zorder=2,fill=False,linewidth=3.5)\n",
    "ax.add_patch(target_pdf_plot)\n",
    "\n",
    "plt.scatter(beta1_sample_initial, beta2_sample_initial,\n",
    "            label='Initial Sample',marker='o',zorder=0,\n",
    "            color='xkcd:sky',alpha=1)\n",
    "\n",
    "plt.scatter(updated_beta1_sample,updated_beta2_sample,\n",
    "            marker='x',s=140,\n",
    "            color='xkcd:red orange',edgecolor='k',zorder=1,alpha=1,\n",
    "            label='Update Sample')\n",
    "\n",
    "plt.xlabel('$\\lambda_1$')\n",
    "plt.ylabel('$\\lambda_2$')\n",
    "plt.title('Data Consistent Update')\n",
    "plt.legend(loc=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update_fig_ADD_shift.savefig('wobbly-update-loc-noise-wrong-model2.png',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computed with Location Noise Modeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defines initial distribution class objects using scipy package (imported at the top)\n",
    "# use \"rvs\" method to generate samples from these objects\n",
    "# use \"pdf\" method to evaluate the pdf at a given value\n",
    "# combine into a matrix of observations\n",
    "beta_initial = np.stack((beta1_sample_initial,beta2_sample_initial),axis=1)\n",
    "\n",
    "# calculate data values\n",
    "loc_sig = loc_noise_std*1.1\n",
    "y_push_forward_LOC = np.array([ Y(beta_initial,locations[0],location_noise=True,loc_noise_pdf=norm(0,loc_sig))[0], \n",
    "                            Y(beta_initial,locations[1],location_noise=True,loc_noise_pdf=norm(0,loc_sig))[0]])\n",
    "\n",
    "# calculate a gaussian kde for the push-forward of the sampled inital values\n",
    "push_forward_kde_pdf_LOC = gaussian_kde(y_push_forward_LOC)\n",
    "\n",
    "\n",
    "# calculate maximum of the ratio\n",
    "M = np.max(data_kde_pdf(y_push_forward_LOC)/push_forward_kde_pdf_LOC(y_push_forward_LOC))\n",
    "\n",
    "# generate random numbers from uniform for accept-reject for each sample value\n",
    "test_value = np.random.uniform(0,1,n_samples)\n",
    "\n",
    "# calculate the ratio for accept reject: data_kde/push_kde/M and compare to test sample\n",
    "# is the kde ratio > test value?\n",
    "accept_or_reject_samples_LOC = np.greater(data_kde_pdf(y_push_forward_LOC)/push_forward_kde_pdf_LOC(y_push_forward_LOC)/M,\n",
    "                            test_value)\n",
    "\n",
    "# accepted values of posterior sample\n",
    "updated_beta1_sample_LOC = beta1_sample_initial[accept_or_reject_samples_LOC]\n",
    "updated_beta2_sample_LOC = beta2_sample_initial[accept_or_reject_samples_LOC]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_fig_LOC_shift, ax = plt.subplots(1)\n",
    "\n",
    "# target distribution\n",
    "target_pdf_plot = patches.Rectangle((lower_a1-0.15,lower_a2+0.6),0.6,0.25,\n",
    "                                   label=\"Target Sample\",\n",
    "                                   edgecolor='xkcd:yellow',facecolor='C2',alpha=1,\n",
    "                                   zorder=2,fill=False,linewidth=3.5)\n",
    "ax.add_patch(target_pdf_plot)\n",
    "\n",
    "plt.scatter(beta1_sample_initial, beta2_sample_initial,marker='o',zorder=0,\n",
    "            color='xkcd:sky',alpha=1, label='Initial Sample')\n",
    "plt.scatter(updated_beta1_sample_LOC,updated_beta2_sample_LOC,\n",
    "            marker='x',s=140,\n",
    "            color='xkcd:red orange',edgecolor='k',zorder=1,alpha=1,\n",
    "            label='Update Sample')\n",
    "\n",
    "#plt.xlim(-1.2,1.2)\n",
    "#plt.ylim(-1.2,1.2)\n",
    "\n",
    "plt.xlabel('$\\lambda_1$')\n",
    "plt.ylabel('$\\lambda_2$')\n",
    "plt.title('Data Consistent Update')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update_fig_LOC_shift.savefig('wobbly-update-loc-noise-correct-model2.png',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check predictability assumption\n",
    "mean_r_ADD = np.mean(data_kde_pdf(y_push_forward)/push_forward_kde_pdf(y_push_forward))\n",
    "mean_r_LOC = np.mean(data_kde_pdf(y_push_forward_LOC)/push_forward_kde_pdf_LOC(y_push_forward_LOC))\n",
    "print(\"For Additive Model: \", mean_r_ADD)\n",
    "print()\n",
    "print(\"For Loc Model: \", mean_r_LOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Predicted vs. Observed Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make data-space grid\n",
    "upper_lim = max(y_push_forward_LOC.max(),y_push_forward.max())\n",
    "lower_lim = min(y_push_forward_LOC.min(),y_push_forward.min())\n",
    "qx = np.linspace(lower_lim,upper_lim,150)\n",
    "qy = np.linspace(lower_lim,upper_lim,150)\n",
    "qX, qY = np.meshgrid(qx, qy)\n",
    "eval_qXY = np.vstack([qX.ravel(),qY.ravel()])\n",
    "\n",
    "# eval points and reshape\n",
    "Z1 = push_forward_kde_pdf(eval_qXY).reshape(qX.shape)\n",
    "Z2 = push_forward_kde_pdf_LOC(eval_qXY).reshape(qX.shape)\n",
    "Z3 = data_kde_pdf(eval_qXY).reshape(qX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_contours_data, ax = plt.subplots(1)\n",
    "\n",
    "level_sets = [0.001,0.01,0.1,0.5,0.75]\n",
    "\n",
    "# ax.scatter(y_predict[i][0],y_predict[i][1],color='xkcd:sky',\n",
    "#            marker='.',s=70,alpha=0.5,label='Predict sample')\n",
    "contours = ax.contour(qX,qY,Z3,levels=level_sets,\n",
    "                      norm=colors.PowerNorm(gamma=0.3),\n",
    "                      cmap='winter',alpha=0.7)\n",
    "# ax.clabel(contours,contours.levels,inline=True)\n",
    "ax.scatter(y_data[0],y_data[1],color='xkcd:red orange',\n",
    "           marker='x',s=70,label='Obs. data')\n",
    "\n",
    "ax.set_title('GKDE of Sampled Height Data')\n",
    "ax.set_xlabel('$y_A$')\n",
    "ax.set_ylabel('$y_B$')\n",
    "# ax.annotate('$\\\\widebar{{r}}={:0.3}$'.format(mean_r[i]), \n",
    "#             xy=(0.1,0.8), xycoords='axes fraction',\n",
    "#             va='top')\n",
    "ax.legend(loc='lower right')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_contours_predict, ax_ADD = plt.subplots(1)\n",
    "fig_contours_predict_LOC, ax_LOC = plt.subplots(1)\n",
    "\n",
    "level_sets = [0.001,0.01,0.1,0.5,0.75]\n",
    "\n",
    "y_predict = [y_push_forward,y_push_forward_LOC]\n",
    "Zs = [Z1,Z2]\n",
    "title_str = ['Unsatisfactory', 'Satisfactory'] #['Add. Noise','Loc. Noise']\n",
    "mean_r = [mean_r_ADD,mean_r_LOC]\n",
    "\n",
    "for i,ax in enumerate([ax_ADD,ax_LOC]):\n",
    "    ax.scatter(y_predict[i][0],y_predict[i][1],color='xkcd:sky',\n",
    "               marker='.',s=70,alpha=0.5,label='Predict sample')\n",
    "    contours = ax.contour(qX,qY,Zs[i],levels=level_sets,\n",
    "                          norm=colors.PowerNorm(gamma=0.3),\n",
    "                          cmap='winter',alpha=0.7)\n",
    "    ax.clabel(contours,contours.levels,inline=True)\n",
    "    ax.scatter(y_data[0],y_data[1],color='xkcd:red orange',\n",
    "               marker='x',s=70,label='Obs. data')\n",
    "\n",
    "    ax.set_title('{} Predictive Model'.format(title_str[i]))\n",
    "    ax.set_xlabel('$y_A$')\n",
    "    ax.set_ylabel('$y_B$')\n",
    "    ax.annotate('$\\\\widebar{{r}}={:0.3}$'.format(mean_r[i]), \n",
    "                xy=(0.1,0.8), xycoords='axes fraction',\n",
    "                va='top')\n",
    "    ax.legend(loc='lower right')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Dissertation Figs\n",
    "diss_labels = ['fig_dissertation_loc-noise-datagen.png',\n",
    "               'fig_dissertation_add-noise-unsatisfactory.png',\n",
    "               'fig_dissertation_loc-noise-satisfactory.png']\n",
    "\n",
    "fig_list = [fig_contours_data,\n",
    "            fig_contours_predict,\n",
    "            fig_contours_predict_LOC]\n",
    "\n",
    "\n",
    "for this_fig, fig_name in zip(fig_list,diss_labels):\n",
    "    print(this_fig,fig_name)\n",
    "#     this_fig.savefig(fig_name,bbox_inches='tight',dpi=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old Reflections and Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# beta_initial.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Consistency Plot Eye-ball Checks**\n",
    "> Note: the following cell is not up to date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# beta_update = np.stack((updated_beta1_sample,updated_beta2_sample),axis=1)\n",
    "\n",
    "# plt.figure()\n",
    "# #plt.hist(y_data_loc1,edgecolor='k',label=\"Data at Loc A\",alpha=0.8,density=True)\n",
    "# plt.hist(y_data_loc2,edgecolor='k',label=\"Data at Loc B\",alpha=0.5,density=True)\n",
    "# #plt.hist(y_push_forward[0],edgecolor='k',density=True,alpha=0.8,label='PF at Loc A')\n",
    "# plt.hist(y_push_forward[1],edgecolor='k',density=True,alpha=0.5,label='PF at Loc B')\n",
    "# #plt.hist(Y(beta_update,locations[0],location_noise=True)[0],\n",
    "# #         edgecolor='k',label=\"UP-PF at Loc A\",alpha=0.8,density=True)\n",
    "# plt.hist(Y(beta_update,locations[1],location_noise=True)[0],\n",
    "#          edgecolor='k',label=\"UP-PF at Loc B\",alpha=0.5,density=True)\n",
    "# plt.title(\"Data Distribution\")\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes and Reflections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "> **Notes from experimentation**: If you choose a location noise model, then we have a model which looks like:\n",
    "\n",
    ">\\begin{align}\n",
    "Q(\\beta_1,\\beta_2)&=y_0+\\beta_1x_1+\\beta_2x_2+(\\beta_1\\xi_1+\\beta_2\\xi_2) \\\\\n",
    "&=y_0+\\beta_1x_1(\\xi_1)+\\beta_2x_2(\\xi_2)\n",
    "\\end{align}\n",
    "\n",
    "Observations:\n",
    "* If there are not enough data points from $\\pi_\\mathcal{D}^{obs}$, then it is possible that the predictability assumption will be violated without us being able to detect this.\n",
    "    * Test Case: If you use location errors and $\\beta_1,\\beta_2>1$, then the nuisance parameters $\\xi_1$ and $\\xi_2$ can have extreme values which cannot be predicted by an additive gaussian noise model. However, this may be not detectable if only a small sample size of $\\xi_1,\\xi_2$ are used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* Choose a model to satisfies the predictability assumption compared to other model inadequacy models which also satisfy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# SAVE ALL FIGS FOR PAPER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slope_fig.savefig('wobbly-target.png',bbox_inches='tight')\n",
    "# data_fig.savefig('wobbly-data.png',bbox_inches='tight')\n",
    "# update_fig.savefig('wobbly-update.png',bbox_inches='tight')\n",
    "# update_fig_noise.savefig('wobbly-update-noise.png',bbox_inches='tight')\n",
    "# loc_fig.savefig('wobbly-plate-loc-noise.png',bbox_inches='tight')\n",
    "# height_fig_locnoise.savefig('wobbly-plate-loc-data.png',bbox_inches='tight')\n",
    "# update_fig_ADD.savefig('wobbly-update-loc-noise-wrong-model.png',bbox_inches='tight')\n",
    "# update_fig_LOC.savefig('wobbly-update-loc-noise-correct-model.png',bbox_inches='tight')\n",
    "# update_fig_ADD_shift.savefig('wobbly-update-loc-noise-wrong-model2.png',bbox_inches='tight')\n",
    "# update_fig_LOC_shift.savefig('wobbly-update-loc-noise-correct-model2.png',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
